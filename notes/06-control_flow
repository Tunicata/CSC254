Control flow mechanisms and their implementation (23 and 28 Oct. 2019)

    T4 due tonight
    A4 due 11:59pm, Fri. Nov. 8

Questions from Midterm?

==============================================================

ORDER of execution matters for statements, and for expressions with side
effects.  Ordering for statements is CONTROL FLOW.

[Expressions have values; statements don't.  Statements are evaluated
for their side effects.  Expressions may have side effects, but don't
necessarily (and it's often considered bad style).]

Principal paradigms for control flow:
    sequencing
    selection
    iteration
    subroutines, recursion (and related control abstractions, e.g. iterators)
    nondeterminacy
    concurrency

----------------------------

Expression evaluation
    infix, prefix operators
    precedence and associativity
        C has 15 levels -- too many to remember
        Pascal has 3 levels -- too few for good semantics
        Fortran has 8; Ada has 6
        I don't like the rules in *any* of these (Fortran probably closest)
            Ada puts and, or at same level
            Pascal if a = b or c = d then
        Lesson: when unsure, use parentheses!

    <<
        consider f(a+b, c, d(e, h), h)
        Why might order of evaluation of arguments matter?
        Why might implementation choose a particular order?
        Should the language say?
    >>        

    ordering of operand evaluation (generally none)

    application of arithmetic identities
        distinguish between commutativity (assumed to be safe)
        and associativity (known to be dangerous)
            (a + b) + c     works if a ~= minint and b ~= maxint and c is small
            a + (b + c)     may not (esp. in FP)
        inviolability of parentheses

    short-circuiting

        if (b != 0 && a/b == c) ...
        if (*p && p->foo) ...
        if (f || messy()) ...

        connection to lazy evaluation of arguments -- e.g., in Haskell

Variables as values v. variables as references
    value-oriented languages
        C, Ada
    reference-oriented languages
        most functional languages (Lisp/Scheme, SML/OCaml/Haskell)
        Smalltalk
    Java deliberately in-between
        built-in types are values
        user-defined types are objects -- references
    C# similar, though user can choose which object variables are values
        ("expanded", in Eiffel terminolody) and which are references

[ Assignment
[   statement (or expression) executed for its side effect(s)
[
[   assignment operators (+=, -=, etc)
[       handy
[       avoid redundant work (or need for optimization)
[       perform side effects exactly once
[
[   C --, ++
[       prefix v. postfix semantics
[       postfix more than syntactic sugar

Initialization v. assignment
    esp. important in OO languages

        foo b;
            // calls no-arg constructor foo::foo()
        foo f = b;
            // calls one-arg "copy constructor" foo::foo(&foo)
            // This is syntactic sugar for 
            //      foo f(b);

        foo b, f;
            // calls no-arg constructor
        f = b;
            // calls foo::operator=(&foo)

    also matters in other languages:
        globals can be statically initialized
        requiring (or defaulting) initialization avoids use of garbage
        also avoids some races in parallel programs
        but has costs

Side Effects
    often discussed in the context of functions
        a side effect is some permanent state change caused by execution of
        function -- some noticable effect of call other than return value.
    in a more general sense, assignment statements provide the ultimate
        example of side effects.  They change the value of a variable.

    SIDE EFFECTS ARE FUNDAMENTAL TO THE WHOLE VON NEUMANN MODEL OF COMPUTING

        In (pure) functional, logic, and dataflow languages, there are no
        such changes.  These languages are called SINGLE-ASSIGNMENT
        languages.  They might better be called "simple definition"
        languages.

[    several langauges outlaw side effects for functions
[        easier to prove things about programs
[        closer to Mathematical intuition
[        easier to optimize
[        (often) easier to understand
[
[        but side effects can be nice
[            consider rand()
[
[    side effects are a particular problem if they affect state used in
[        other parts of the expression in which a function call appears,
[        because many languages don't specify an evaluation order for
[        components of an expression.  It's nice not to specify an
[        order, because it makes it easier to optimize.  Fortran says
[        it's ok to have side effects, but they aren't allowed to change
[        other parts of the expression containing the function call.
[        Unfortunately, compilers can't check this completely without
[        language restrictions, and most don't try to do so.
[
[    BTW, note the difference between
[        checked errors
[        implementation-defined behavior
[        unchecked errors
[            Ada calls these "erroneous"; C calls them "undefined behavior"

----------------------------------------
sequencing
    specifies a linear ordering on statements
    very imperative, Von-Neumann

selection
    sequential if statements
        if ... then ... else

        if ... then ... elsif ... else

        (cond
            (C1) (E1)
            (C2) (E2)
            ...
            (Cn) (En)
            (T)  (Et)
        )

        match e with
        | pat1 when cond1 ->
        | pat2 when cond2 ->
        | ...
        | patN when condN ->
        | _               ->

        value of explicit terminators or begin/end (or {}) brackets
        need for elsif (elif)

    jump code
        For selection and logically-controlled loops.
        No point in computing a Boolean value into a register, then
        testing it.

        Especially useful in the presence of short-circuiting.
        Example (section 6.4.1 of book):

            if ((A > B) and (C > D)) or (E <> F) then
                 then_clause
            else
                else_clause

            w/out short-circuiting (as in, e.g., Pascal):

                r1 := A             -- load
                r2 := B
                r1 := r1 > r2
                r2 := C
                r3 := D
                r2 := r2 > r3
                r1 := r1 & r2
                r2 := E
                r3 := F
                r2 := r2 <> r3
                r1 := r1 | r2
                if r1 = 0 goto L2
            L1: then_clause         -- label not actually used
                goto L3
            L2: else_clause
            L3:

            with short-circuiting (as in, e.g., C):

                r1 := A
                r2 := B
                if r1 <= r2 goto L4
                r1 := C
                r2 := D
                if r1 > r2 goto L1
            L4: r1 := E
                r2 := F
                if r1 = r2 goto L2
            L1: then_clause
                goto L3
            L2: else_clause
            L3:

            Note that this not only avoids performing unnecessary
            comparisons; it also avoids the AND and OR instructions.

    guarded commands
        example of non-determinacy
            if
                cond1 -> stmt1
            []  cond2 -> stmt2
                ...
            []  condN -> stmtN
            fi
        similar version for loops

    fortran computed gotos

    case/switch (introduced in Algol-W)
        nobody lets labels overlap

    <<
        what should happen if there isn't a matching label for value?
    >>

            Ada: forbid at compile time
            C: no-op
            Pascal: dynamic semantic error

    <<
        what implementation should we use for
        3:      1:      1:          1..48:
        5:      2:      59:         97..283:
        7:      3:      187:        900..1024:
        9:      ...     ...         ...
                100:    1000000:    12345..67890:
    >>

    case implementation
        sequential testing
            small number of choices, non-dense range
        characteristic array (jump table)
            dense range
        hashing
            non-dense range w/out range labels
        binary search
            large range, range labels
        (prob. don't need search tree)

        should ranges be allowed in the label list?
            they make it easy to state things for which a jump table or
            hash table is awful: can be done efficiently with binary search

========================================
iteration

logically controlled        v. enumeration controlled
"while condition is true"   v. "for every element of set"
In the latter case, the number of elements (and their identities) are
known before we even start the loop (and in general, we don't want the
values we iterate over to depend on anything we do in early iterations).

logically-controlled

    pre-test (while)
    post-test (repeat)
    one-and-a-half loops (loop with exit)
        labels for non-closest exit?

    implementation options:

        top:
            r1 := condition
            if !r1 goto continue
            < loop body >
            goto top
        continue:

    That has two branches in every iteration.

            r1 := condition
            if !r1 goto skip
        top:
            < loop body >
            r1 := condition
            if r1 goto top
        skip:

    That evaluates the condition twice.  Not a big deal if it doesn't
    bloat code size.  If it's complicated we can do this instead:

            goto test
        top:
            < loop body >
        test:
            r1 := condition
            if r1 goto top

    That has one extra jump, but only one copy of the test.

    C-style for loop
        semantically clean, but NOT really a for loop
        hard to apply the various optimizations possible for "real"
            for loops

        for (i = first; i <= last; i+= step) {
            ...
        }

        ~=

        i = first;
        while (i <= last) {
            ...
            i += step;
        }

enumeration-controlled

        for v in my_set /* in my favorite order */ do
            ...
        end

    Most common case:

        /* Modula-2 syntax */
        i : integer;
        ...
        for i := first to last by step do
            ...
        end

    <<
        How might we implement this?  Consider

            i := first
            goto test
      top:  ...
            i += step
      test: if i <= last goto top

        What can go wrong?
    >>

    Problems -- generally fixed in Ada and Fortran 90, to some extent
    in Modula-2.

        empty bounds
            shouldn't execute (did in Fortran I)

        changes to bounds or stepsize within loop
            calculated up front in modern languages

            direction of step
                constant stepsize
                "downto" (Pascal)
                "in reverse" (Ada)

        changes to loop variable within loop
            not generally allowed in modern langauges

        value after the loop
            especially at end-of-legal range for type (overflow?)

            if local to loop, can't even name afterward, so it's just
            an implementation issue, not a semantic one

        iteration count translation technique
            needed in Fortran, which has run-time step
            helpful any time the end value may be the last valid one

        gotos in and out
            modern langauges allow only out, and structure as
            exit/break/return (or exception)

------------
    iterators
        supply a for loop with the members of a set
        abstraction/generalization of the 'from A to B by C' sorts of
            stuff you see built-in in older languages

        pioneered by Clu:
            for i in iterator do ... end
            built-in iterators for from_to, from_to_by, etc.

        wonderful for iterating over arbitrary user-defined sets
            very good for abstraction; for loop doesn't have to know
            whether set is a linked list, hash table, dense array, etc.

        may be true iterators (as in Clu, C#, Icon, Python, Ruby)
        or interface-based approximation ("iterator objects", as in
        Euclid, Java, and C++)

        in Python:

            def uptoby(lo, hi, step):
                while True:
                    if (step > 0 and lo > hi) or (step < 0 and lo < hi): return
                    yield lo
                    lo += step  # ignore overflow

    iterator objects (Euclid, C++, Java)

        Standard interface for abstraction to drive for loops.
        Supported in Euclid and Java with special loop syntax, and
        in C++ through clever use of standard constructor and
        operator overload mechanisms.

        In Java:

            List<foo> myList = ...;

            for (foo o : myList) {
                // use object o
            }

        requires that the to-be-iterated class (here, List)
        implements the Iterable interface, which exports a method

            public Iterator<T> iterator()

        where Iterator is an interface exporting methods

            public boolean hasNext()
        and
            public T next()

        The for loop is syntactic sugar for

            for (Iterator<foo> i = myList.iterator(); i.hasNext();) {
                foo o = i.next();
                // use object o
            }

        C++ version looks like

            list<foo> my_list;
            ...
            for (list<foo>::const_iterator i = my_list.begin();
                    i != my_list.end(); i++) {
                // make use of *i or i->field_name
            }

        Don't have to have an equivalent of the Iterator interface (it's
        just a convention), because C++ individually type-checks every
        use of a generic (template).

        All the standard library collection/container classes
        support iterators, in both languages.

------------
    true iterators (Clu, Icon, C#, Python)
        iterator itself looks like a procedure, except it can include
            "yield" statements that produce intermediate values.
        when the iterator returns, the loop terminates

    C# for loop resembles that of Java:

        foreach (foo o in myList) {
            // use object o
        }

    This is syntactic sugar for

        for (IEnumerator<foo> i = myList.GetEnumerator(); i.MoveNext()) {
            foo o = i.Current;
            // use object o
        }

    Current is an *accessor* -- a special method supporting field-like
    access:

    public object Current {
        get {
            return ...;
        }
        put {
            ... = value;
        }
    }

    In contrast to Java, you don't need to hand-create the hasNext()
    [MoveNext()] and next() [Current] methods.  The compiler does this
    automatically when your class implements the IEnumerable interface
    and has an iterator -- a method containing yield statements and
    "returning" an IEnumerator:

    class List : IEnumerable {
        ...
        public IEnumerator GetEnumerator() {
            node n = head;
            while (n != null) {
                yield return n.content;
                n = n.next;
            }                   // NB: no return stmt
        }
    }

    If you want to be able to have multiple iteration orders, your class
    can have multiple methods that each return an IEnumerator.  Then you
    can say, e.g.

        foreach (object o in myTree.InPreOrder) { ...

        foreach (object o in myTree.InPostOrder) { ...

    detail:
        IEnumerator implements MoveNext and Current (also Reset)
        IEnumerable implements GetEnumerator, which returns an IEnumerator

------------
loop body as lambda (Smalltalk, Scheme, ML, Ruby, ...)

    Scheme:
        (define show (lambda (i) (begin (display i) (newline))))

        (define upto
          (lambda (a b)
            (lambda (f)
              (letrec ((helper (lambda (i)
                                 (if (> i b) '()
                                   (begin
                                    (f i) 
                                    (helper (+ i 1)))))))
                (helper a)))))

        ((upto 1 10) show) =>
            1
            2
            3
            4
            5
            6
            7
            8
            9
            10
            ()

    OCaml:
        open Printf;;
        let show n = printf "%d\n" n;;

        let upto lo hi =
          fun f -> let rec helper i =
                     if i > hi then ()
                     else (f i ; helper (i + 1)) in
          helper lo;;

        upto 1 10 show;; =>
            1
            2
            3
            4
            5
            6
            7
            8
            9
            10
            - : unit = ()

    Ruby:

        sum = 0                                 => 0
        [ 1, 2, 3 ].each { |i| sum += i }       => [1, 2, 3]  # array itself
        sum                                     => 6

        Here the (parameterized) brace-enclosed block is passed to the each
        method as a parameter.

        There's also more conventional-looking syntax:

            sum = 0
            for i in [1, 2, 3] do       # 'do' is optional
                sum += i
            end
            sum

        The for loop is syntactic sugar for a call to each.

        Here's a more OO alternative:

            sum = 0
            1.upto 3 {|i| sum += i}
            sum

        or instead of using braces:

            sum = 0
            i.upto 3 do |i| sum += i end
            sum

        You can write your own iterators using 'yield'.

            class Array 
            def find 
                for i in 0...size 
                    value = self[i] 
                    return value if yield(value) 
                end 
                return nil 
            end 
            end 
            ...
            [1, 3, 5, 7, 9].find {|v| v*v > 30 }  => 7 

        Think of yield as invoking the block that was juxtaposed
        ("associated") with the call to the iterator.

        (FWIW, the array class already has a find method in Ruby, but we
        can redefine it, and it probably looks like this anyway.)

        Blocks can also be turned into first-class closures, with
        unlimited extent:

            def nTimes(aThing)
                # Ruby, like most scripting languages, is dynamically typed
                return proc { |n| aThing * n }
            end

            In recent Ruby, -> is a synonym for proc

            p1 = nTimes(3)
            p2 = nTimes("foo")
            p1.call(4)              => 12
            p2.call(4)              => "foofoofoofoo"

        This lets us build higher-level functions.  Here's reduction
        for arrays:

          class Array
            def reduce(n)
                each { |value| n = yield (n, value) }   # that's self.each
                    # yield invokes (just once) the block associated
                    # with the call to reduce
                n   // return value
            end
            def sum
                reduce(0) { |n, value| n + value }
            end
            def product
                reduce(1) { |n, value| n * value }
            end
          end

            [2, 4, 6].sum       => 12
            [2, 4, 6].product   => 48

        All in all Ruby is pretty cool.  Check it out.
        (I do wish it let you associate more than one block with a call.)

------------
implementation of true iterators (section 8.6.3-CS)

coroutines or threads
    overkill

single-stack
    used in Clu
    works, but would confuse a standard debugger, and not compatible
        with some conventions for argument passing

implicit iterator object        
    kinda cool; used in C# and Python

block as lambda expression (Ruby, functional languages)

----------------------------

recursion
    equally powerful to iteration, and as efficient in cases where you
    can use tail recursion.

    mechanical transformations back and forth
    often more intuitive (sometimes less)
    *naive* implementation less efficient
    no special syntax required
    fundamental to functional languages like Scheme

    tail recursion
 
[ Scheme:
[           (define gcd (lambda (a b)
[               (cond ((= a b) a)
[                     ((< a b) (gcd a (- b a)))
[                     ((> a b) (gcd (- a b) b)))))

[ Haskell:
[           gcd :: (Integral a) => a -> a -> a
[           gcd b c
[               | b == c = b
[               | b < c  = gcd b (c - b)
[               | c < b  = gcd (b - c) c

[ OCaml:
            let rec gcd b c =
              if b = c then b
              else if b < c then gcd b (c - b)
              else gcd (b - c) c;;
 
        implemented as
 
            gcd (b c)
            start:
                if b = c
                    return b
                if b < c
                    c := c - b
                    goto start
                if b > c
                    b := b - c
                    goto start
                    
    changes to create tail recursion (e.g. pass along an accumulator)
 
[ Scheme:
[       (define summation (lambda (f low high)
[           (if (= low high)
[               (f low)                                       ; then part
[               (+ (f low) (summation f (+ low 1) high)))))   ; else part

[ Haskell:
[       summation :: (Integral a) => (a -> a) -> a -> a -> a
[       summation f low high
[           | low == high   = f low
[           | otherwise     = f low + summation f (low+1) high

[ OCaml:
        let rec summation f low high =
          if low == high then f low
          else f low + summation f (low+1) high;;
 
    becomes
 
[ Scheme:
[       (define summation (lambda (f low high subtotal)
[           (if (= low high)
[               (+ subtotal (f low))
[               (summation f (+ low 1) high (+ subtotal (f low))))))

[ Haskell:
[       summation2 :: (Integral a) => (a -> a) -> a -> a -> a -> a
[       summation2 f low high st
[           | low == high   = st + f low
[           | otherwise     = summation2 f (low+1) high (st + f low)

[ OCaml:
        let rec summation2 f low high st =
          if low == high then st + f low
          else summation2 f (low+1) high (st + f low);;
 
    and then
 
[ Scheme:
[       (define summation (lambda (f low high)
[         (letrec ((sum-helper (lambda (low subtotal)
[                    (let ((new_subtotal (+ subtotal (f low))))
[                      (if (= low high)
[                          new_subtotal
[                          (sum-helper (+ low 1) new_subtotal))))))
[           (sum-helper low 0))))

[ Haskell:
[       summation3 :: (Integral a) => (a -> a) -> a -> a -> a
[       summation3 f low high =
[           helper low 0
[           where helper low st
[                   | low == high   = new_st
[                   | otherwise     = helper (low+1) new_st
[                   where new_st = st + f low

[ OCaml:
        let summation3 f low high =
          let rec helper low st =
            let new_st = st + f low in
            if low == high then new_st
            else helper (low+1) new_st in
          helper low 0;;    
 
    More generally (absent an associative operator), pass along a
    *continuation*.
 
    This is perfectly natural to someone used to programming in a
    functional language.  Note that the summation example depends for
    correctness on the associativity of addition.  To sum the elements
    in the *same* order we could have counted down from high instead of
    up from low, but that makes a more drastic change to the structure
    of the recursive calls.
 
    There is no perfectly general algorithm to discover tail-recursive
    versions of functions, but compilers for functional languages
    recognize all sorts of common cases.
 
    Sisal and pH have "iterative" syntax for tail recursion:
 
        function sum (f : function (n : integer returns integer),
                      low : integer, high : integer returns integer)
        for initial
            st := f (low);
        while low <= high
            low := old low + 1
            st := old st + f (low)
        returns value of st
        end for
        end function
    
    Sisal compiler was *really* good at finding tail recursive forms.

concurrency
    specifies that statements are to occur (at least logically) concurrently
    concurrency is fundamental to probably half the research in computer
        science today
    subject of chapter 15

nondeterminacy
    choice "doesn't matter"
    periodically popular, promoted by Dijkstra for use with selection
    can apply to execution order as well
    useful for certain kinds of concurrency

    process server
        do
            receive read request ->
            reply with data
        []
            receive write request ->
            update data and reply
        od

    also nice for certain axiomatic proof schemes
    raises issues of "randomness", "fairness", "liveness", etc.
    